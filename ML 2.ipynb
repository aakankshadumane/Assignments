{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "# can they be mitigated?\n",
    "Underfitting:  It represents the inability of the model to learn the training data effectively result in poor \n",
    "    performance both on the training and testing data.The model has High bias and low variance.\n",
    "To Reduce Underfitting:\n",
    "    Increase model complexity.\n",
    "    Increase the number of features, performing feature engineering.\n",
    "    Remove noise from the data.\n",
    "    Increase the duration of training to get better results.\n",
    "    \n",
    "Overfitting: When a model gets trained with so much data, it starts learning from the noise and inaccurate data in \n",
    "    our data set. And when testing with test data results in High variance, then the model does not categorize the \n",
    "    data correctly, because of too many details and noise.The model has High variance and low bias.\n",
    "To Reduce Overfitting:\n",
    "    Increase training data.\n",
    "    Reduce model complexity.\n",
    "    Early stopping during the training phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: How can we reduce overfitting? Explain in brief.\n",
    "1. Increase training data. - Overfitting can occur if training data if too small. Consider having more data points\n",
    "so as the model can find more appropriate patterns\n",
    "2. Reduce model complexity.\n",
    "3. Early stopping during the training phase - Overfitting occurs due to learning noise from dataset. Early stopping \n",
    "can prevent those losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba83f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "A machine learning algorithm is said to have underfitting when a model is too simple to capture data complexities. \n",
    "It represents the inability of the model to learn the training data effectively result in poor performance both on\n",
    "the training and testing data. In simple terms, an underfit model’s are inaccurate, especially when applied to new,\n",
    "unseen examples. It mainly happens when we uses very simple model with overly simplified assumptions.\n",
    "\n",
    "Scenarios for Underfitting:\n",
    "    1. The model is too simple, So it may be not capable to represent the complexities in the data.\n",
    "    2. The input features which is used to train the model is not the adequate representations of underlying factors \n",
    "    influencing the target variable.\n",
    "    3. The size of the training dataset used is not enough.\n",
    "    4. Excessive regularization are used to prevent the overfitting, which constraint the model to capture the data well.\n",
    "    5. Features are not scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983898e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "# variance, and how do they affect model performance?\n",
    "If the algorithm is too simple then it may be on high bias and low variance condition and thus is error-prone.\n",
    "If algorithms fit too complex then it may be on high variance and low bias. So we need to find the right/good balance \n",
    "without overfitting and underfitting the data.\n",
    "A good model should have balance between bias and variance such that it minimizes the total error.\n",
    "Bias and variance are inversely connected. It is impossible to have an ML model with a low bias and a low variance.\n",
    "When a data engineer modifies the ML algorithm to better fit a given data set, it will lead to low bias—but it will\n",
    "increase variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec40bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "# How can you determine whether your model is overfitting or underfitting?\n",
    "To Detect Overfitting: \n",
    "    Training data gives good accuracy but there is high error rate in the testing data. This indicates overfitting.\n",
    "    \n",
    "To Detect Underfitting:\n",
    "    If training and testing data both has low accuracy, then model is considered to have Underfitting.It has high \n",
    "    bias and low variance.\n",
    "\n",
    "A model is underfitting the training data when the model performs poorly on the training data. This is because the model \n",
    "is unable to capture the relationship between the input examples and the target values. Your model is overfitting your \n",
    "training data when you see that the model performs well on the training data but does not perform well on the evaluation\n",
    "data. This is because the model is memorizing the data it has seen and is unable to generalize to unseen examples.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9927408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "# and high variance models, and how do they differ in terms of their performance?\n",
    "Bias refers to the difference between predicted values and actual values.\n",
    "Variance says about how much a random variable deviates from its expected value.\n",
    "Low bias suggests less assumptions about the form of the target function, while high bias suggests more \n",
    "assumptions about the form of the target function.\n",
    "Variance is the amount of variation that the estimate of the target function will change if different \n",
    "training data was used. \n",
    "High bias models (underfitting) have a simplified representation of the underlying data and perform poorly both\n",
    "on training and validation data due to systematic errors.\n",
    "High variance models (overfitting) have a complex representation of the training data and perform exceptionally \n",
    "well on the training data but poorly on validation data due to their inability to generalize.\n",
    "Examples:\n",
    "High Bias - Linear Regression\n",
    "Low Bias - Decision Tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "# some common regularization techniques and how they work.\n",
    "\n",
    "Regularization basically adds the penalty as model complexity increases. Regularization parameter penalizes \n",
    "all the parameters except intercept so that model generalizes the data and won’t overfit.\n",
    "\n",
    "Types of Regularization:\n",
    "L1 regularization technique/Lasso Regression : adds “absolute value of magnitude” of coefficient as penalty \n",
    "    term to the loss function.\n",
    "L2 Regularization/Ridge Regression : adds squared magnitude of coefficient as penalty term to the loss function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
