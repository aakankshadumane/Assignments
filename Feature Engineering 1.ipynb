{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaef0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "# algorithms that are not affected by missing values.\n",
    "Missing values in a dataset refer to the absence of data for certain observations or variables. \n",
    "They are represented as null, NaN, or some other marker depending on the data format. \n",
    "\n",
    "It is essential to handle missing values for several reasons:\n",
    "Biased Analysis: If missing values are not handled, they can introduce bias into your analysis. \n",
    "Models trained on data with missing values may produce inaccurate or skewed results.\n",
    "\n",
    "Reduced Sample Size: Missing values reduce the effective sample size, potentially leading \n",
    "to a loss of precision in your analysis.\n",
    "\n",
    "Model Performance: Many machine learning algorithms cannot handle missing values and will throw\n",
    "errors if they encounter them during training or inference. Handling missing values allows you to \n",
    "use a broader range of models.\n",
    "\n",
    "Data Integrity: Handling missing values ensures the integrity and reliability of your dataset, \n",
    "making it more suitable for reporting and decision-making.\n",
    "\n",
    "Algorithms that are not affected by missing values include:\n",
    "Decision Trees\n",
    "Random Forests\n",
    "k-Nearest Neighbors (k-NN)\n",
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab3ae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  5.0\n",
       "1  2.0  NaN\n",
       "2  NaN  NaN\n",
       "3  4.0  8.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import pandas as pd\n",
    "data = {'A': [1, 2, None, 4],\n",
    "        'B': [5, None, None, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896978cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  5.0\n",
      "3  4.0  8.0\n"
     ]
    }
   ],
   "source": [
    "# Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "1. Dropping Missing data rows/columns: Only suitable if less amount of missing data is present.\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4],\n",
    "        'B': [5, None, None, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591e0b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A    B\n",
      "0  1.000000  5.0\n",
      "1  2.000000  NaN\n",
      "2  2.333333  NaN\n",
      "3  4.000000  8.0\n"
     ]
    }
   ],
   "source": [
    "2. Fill missing values with the mean, median, or mode of the respective column.\n",
    "\n",
    "data = {'A': [1, 2, None, 4],\n",
    "        'B': [5, None, None, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Replace missing values with the mean of column A\n",
    "df['A'].fillna(df['A'].mean(), inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b298691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  5.0\n",
      "1  2.0  0.0\n",
      "2  0.0  0.0\n",
      "3  4.0  8.0\n"
     ]
    }
   ],
   "source": [
    "3. Fill missing values with a constant.\n",
    "\n",
    "data = {'A': [1, 2, None, 4],\n",
    "        'B': [5, None, None, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Replace missing values with a constant (e.g., 0)\n",
    "df.fillna(0, inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13919f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  3.0\n",
      "3  4.0\n",
      "4  5.0\n"
     ]
    }
   ],
   "source": [
    "# 4. Fill missing values using interpolation methods like linear, polynomial, or spline.\n",
    "\n",
    "data = {'A': [1, None, 3, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Interpolate missing values using linear interpolation\n",
    "df['A'].interpolate(method='linear', inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "Imbalanced data refers to a situation in a classification problem where the distribution of classes\n",
    "is highly unequal. In other words, one class has significantly more instances than the other(s). \n",
    "For example, in a binary classification problem where you are predicting whether a transaction is \n",
    "fraudulent or not, you might have 95% of the transactions as non-fraudulent and only 5% as fraudulent.\n",
    "This is an imbalanced dataset.\n",
    "\n",
    "If Imbalanced data is not handled:\n",
    "1. Biased Model:The model will work good on majority class but not on minority clas.\n",
    "2. There can be Misclassification of Minority Class\n",
    "3. Accuracy can be misleading in imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a69bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "# sampling are required.\n",
    "1. Up-sampling (Over-sampling):\n",
    "Up-sampling involves increasing the number of instances in the minority class to balance the \n",
    "class distribution.\n",
    "Ex: Suppose you have a fraud detection dataset with 95% non-fraudulent transactions and only \n",
    "    5% fraudulent ones. To balance the dataset, you can up-sample the fraudulent transactions.\n",
    "    \n",
    "2. Down-sampling (Under-sampling):\n",
    "Down-sampling involves reducing the number of instances in the majority class to balance the \n",
    "class distribution.\n",
    "Ex: Consider a medical dataset where you are predicting a rare disease. You have a large dataset\n",
    "    with 95% non-disease cases and 5% disease cases. In this case, you might choose to down-sample\n",
    "    the non-disease cases to match the number of disease cases,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: What is data Augmentation? Explain SMOTE.\n",
    "Data augmentation is a technique used in machine learning and data preprocessing to artificially \n",
    "increase the size of a dataset by creating variations of the existing data. \n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a specific data augmentation technique used \n",
    "primarily to address class imbalance problems in classification tasks, especially when dealing with\n",
    "imbalanced datasets.By generating synthetic samples, it introduces diversity into the minority class, \n",
    "making it less likely for the model to overfit to the minority class while training. This can result\n",
    "in improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "Outliers are data points in a dataset that significantly deviate from the majority of the data points.\n",
    "They are extreme values that lie far away from the central tendency of a distribution.\n",
    "It is essential to handle outliers because:\n",
    "1. Outliers can distort basic statistical measures such as the mean and standard deviation, leading \n",
    "to inaccurate summaries of the data.\n",
    "2.  Outliers can have a significant impact on data visualizations like histograms, box plots, and \n",
    "scatter plots.This can make interpreting difficult.\n",
    "3. They can negatively affect the performance of machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c60774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "# the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "Deletion:\n",
    "Listwise Deletion (Complete-Case Analysis): Remove rows or columns with missing values entirely. \n",
    "This is suitable when missing values are minimal and do not significantly impact the analysis. However, \n",
    "it may lead to a loss of information.\n",
    "\n",
    "Imputation:\n",
    "Mean/Median Imputation: Replace missing values with the mean (for continuous data) or median \n",
    "(for ordinal or skewed data) of the respective variable.\n",
    "Mode Imputation: For categorical data, replace missing values with the mode of the variable.\n",
    "Constant Imputation: Replace missing values with a predefined constant (e.g., 0 or -1).\n",
    "Interpolation: Use interpolation methods like linear or spline interpolation to estimate missing\n",
    "values based on neighboring data points in time series or ordered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "# some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "# to the missing data?\n",
    "\n",
    "Visual Inspection:\n",
    "Create graphical representations of the missing data patterns. Plot missing data indicators across variables\n",
    "or rows to visually identify any patterns or clusters of missing values.\n",
    "\n",
    "Summary Statistics:\n",
    "Calculate summary statistics for variables with missing data and compare them to those without missing data.\n",
    "If there are systematic differences in summary statistics, it may indicate that the data is not missing \n",
    "completely at random.\n",
    "\n",
    "Correlation Analysis:\n",
    "Examine the correlations between variables with missing data and other variables in the dataset. If missingness\n",
    "in one variable is correlated with the values of another variable, it may suggest that data is missing at random\n",
    "or missing not at random.\n",
    "\n",
    "Data Imputation and Comparison:\n",
    "Impute missing data using different imputation methods and compare the results. If the choice of imputation \n",
    "method significantly impacts the results, it may suggest that the missing data is not random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "# dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "# can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "This is a Imbalanced dataset. To Evaluate such dataset, one needs to handle the imbalance first\n",
    "1. Resample the training dataset using Undersampling or Oversampling techniques\n",
    "2. Using Ensemble techniques to combine multiple models and generate results\n",
    "\n",
    "Using Evaluation metrics apart from Accuracy.\n",
    "Precision/Specificity: how many selected instances are relevant.\n",
    "Recall/Sensitivity: how many relevant instances are selected.\n",
    "F1 score: harmonic mean of precision and recall.\n",
    "MCC: correlation coefficient between the observed and predicted binary classifications.\n",
    "AUC: relation between true-positive rate and false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d711aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "# unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "# balance the dataset and down-sample the majority class?\n",
    "Downsampling or Undersampling can be used to balance the dataset.\n",
    "Methods to Down sample are:\n",
    "    1. Random : It removes the samples from majority class with or without replacement. This can discard useful\n",
    "    samples as well.\n",
    "        \n",
    "    2. Nearmiss : Majority class values are Randomly eliminated. It finds the distance between instances of majority\n",
    "    class and remove the instances which are very close to each other.This increases sapces between two classes.\n",
    "    \n",
    "    3. Tomeklinks : Majority class links are removed until all minimally distanced nearest neighbor pairs are of\n",
    "    the same class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "# project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "# balance the dataset and up-sample the minority class?\n",
    "Upsampling techniques are as follows:\n",
    "    1. Random : Training data is provided with multiple copies of minority classes. Some of classes are randomly\n",
    "    chosen with replacement.\n",
    "    \n",
    "    2. SMOTE (Synthetic minority oversampling technique) : It synthesises new minority instances between existing\n",
    "    minority instances. It generates the virtual training records by linear interpolation for the minority class. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e01ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad8382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df055956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
